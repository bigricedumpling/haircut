import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import pandas as pd
from streamlit_mermaid import st_mermaid
import data_processor_final as data_processor # å¯¼å…¥æˆ‘ä»¬æœ€ç»ˆçš„æ•°æ®å¤„ç†å™¨
import logging
import math # å¯¼å…¥æ•°å­¦åº“ç”¨äºå¸ƒå±€
import numpy as np # å¯¼å…¥ numpy ç”¨äºå¸ƒå±€
import networkx as nx # ã€ã€ã€ æ–°å¢ï¼šç”¨äºç”ŸæˆåŠ›å¯¼å‘çŸ¥è¯†å›¾è°± ã€‘ã€‘ã€‘
from itertools import combinations # ã€ã€ã€ æ–°å¢ï¼šç”¨äºè®¡ç®—è¾¹çš„æƒé‡ ã€‘ã€‘ã€‘
from collections import Counter

# --- 0. é¡µé¢é…ç½®ä¸æ ·å¼åŠ è½½ ---
st.set_page_config(
    page_title="æŸ“å‘æ¶ˆè´¹å“æ·±åº¦æ´å¯Ÿ (V-Final-4)",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# è§†è§‰ä¼˜åŒ–
PLOT_TEMPLATE = "plotly_white"
PLOT_COLOR = "rgb(70, 130, 180)" # ä¸»è‰²: SteelBlue (é’¢è“è‰²)
PLOT_COLOR_SEQUENCE = px.colors.sequential.Blues # æ¸å˜: V1çš„"è“è‰²æ¸å˜"
GRAY_COLOR = 'rgb(200, 200, 200)' # è¾…è‰²: æµ…ç°

def load_css(file_name):
    try:
        with open(file_name, encoding='utf-8') as f:
            st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
    except FileNotFoundError:
        st.warning("style.css æ–‡ä»¶æœªæ‰¾åˆ°ã€‚å°†ä½¿ç”¨é»˜è®¤æ ·å¼ã€‚")

def create_insight_box(text):
    st.markdown(f"<div class='custom-insight-box'>{text}</div>", unsafe_allow_html=True)

# --- 1. å›¾è¡¨ç»˜åˆ¶æ¨¡å— (Plotters) ---

# --- 1A. æ–¹æ³•è®ºå›¾è¡¨ (æ— æ”¹åŠ¨) ---
def plot_methodology_flow():
    """å›¾ 1: åˆ†ææ–¹æ³•è®º (Mermaid æµç¨‹å›¾)"""
    mermaid_code = """
    graph TD
        A(1. å…³é”®è¯ç­–ç•¥<br/>å…¨å“ç±»å…³é”®è¯åº“) --> B(2. å¤šæºæ•°æ®é‡‡é›†<br/>æ·˜å®/äº¬ä¸œ/å°çº¢ä¹¦/å¾®åš/è¯„è®º);
        B --> C{3. P-Tag å¼•æ“<br/>æ•°æ®æ¸…æ´—ä¸æ ‡ç­¾åŒ–};
        C --> D[4. å¸‚åœºæ ¼å±€åˆ†æ<br/>ä»·æ ¼/å“ç‰Œ/åŒºåŸŸ];
        C --> E[5. äº§å“çŸ©é˜µåˆ†æ<br/>è‰²ç³»/åŠŸæ•ˆ/äº§å“ç±»å‹];
        C --> F[6. ç¤¾åª’å£°é‡éªŒè¯<br/>å¹³å°/çƒ­ç‚¹/æº¢ä»·];
        C --> G[7. æ ¸å¿ƒè¯‰æ±‚æ·±æŒ–<br/>è¯­ä¹‰å…±ç°/çŸ¥è¯†å›¾è°±];
        C --> H[8. ç”¨æˆ·å£ç¢‘éªŒè¯<br/>è¯„è®ºæƒ…æ„Ÿ];
        D & E & F & G & H --> I((<b>æœ€ç»ˆæ´å¯ŸæŠ¥å‘Š</b>));

        classDef default fill:#fff,stroke:#ddd,stroke-width:1px,font-size:14px;
        class C fill:#0068c9,color:#fff,font-weight:bold,stroke-width:0px;
        class I fill:#1a1a1a,color:#fff,font-weight:bold,stroke-width:0px;
    """
    try:
        st_mermaid(mermaid_code, height="550px")
    except Exception as e:
        st.error(f"Mermaid æµç¨‹å›¾æ¸²æŸ“å¤±è´¥: {e}")
        st.code(mermaid_code, language="mermaid")

def plot_meta_data_funnel(raw_counts):
    """å›¾ 2: æ•°æ®é‡‡é›†æ¼æ–— (KPIæŒ‡æ ‡å¡)"""
    st.subheader("å›¾ 2: æ•°æ®é‡‡é›†æ¼æ–—")
    cols = st.columns(5)
    cols[0].metric("ç”µå•†å•†å“ (SKU)", f"{raw_counts['æ·˜å®å•†å“'] + raw_counts['äº¬ä¸œå•†å“']:,}")
    cols[1].metric("ç¤¾åª’å¸–å­ (Posts)", f"{raw_counts['å°çº¢ä¹¦ç¬”è®°'] + raw_counts['å¾®åšå¸–å­']:,}")
    cols[2].metric("ç”¨æˆ·è¯„è®º (UGC)", f"{raw_counts['æ·˜å®è¯„è®º']:,}")
    cols[3].metric("ç”µå•†å…³é”®è¯ (Query)", f"{raw_counts['ç”µå•†å…³é”®è¯']:,}")
    cols[4].metric("ç¤¾äº¤å…³é”®è¯ (Query)", f"{raw_counts['ç¤¾äº¤å…³é”®è¯']:,}")

def plot_meta_source_volume(raw_data_counts):
    """å›¾ 3: æœ¬æ¬¡åˆ†ææ•°æ®æºæ€»è§ˆ (æŸ±çŠ¶å›¾)"""
    st.subheader("å›¾ 3: æœ¬æ¬¡åˆ†ææ•°æ®æºæ€»è§ˆ")
    data = {
        'å¹³å°': ['æ·˜å®å•†å“', 'äº¬ä¸œå•†å“', 'å°çº¢ä¹¦ç¬”è®°', 'å¾®åšå¸–å­', 'æ·˜å®è¯„è®º'],
        'æ•°æ®é‡': [
            raw_data_counts.get('æ·˜å®å•†å“', 0), 
            raw_data_counts.get('äº¬ä¸œå•†å“', 0), 
            raw_data_counts.get('å°çº¢ä¹¦ç¬”è®°', 0), 
            raw_data_counts.get('å¾®åšå¸–å­', 0), 
            raw_data_counts.get('æ·˜å®è¯„è®º', 0)
        ]
    }
    df = pd.DataFrame(data)
    df = df[df['æ•°æ®é‡'] > 0].sort_values('æ•°æ®é‡', ascending=False)
    
    fig = px.bar(df, x='å¹³å°', y='æ•°æ®é‡', 
                 text='æ•°æ®é‡', color='å¹³å°', 
                 color_discrete_sequence=px.colors.sequential.Blues_r[::2])
    fig.update_layout(template=PLOT_TEMPLATE, showlegend=False)
    fig.update_traces(textposition='outside')
    st.plotly_chart(fig, use_container_width=True)

def plot_keyword_analysis_treemap(keyword_strategy):
    """å›¾ 4: æ ¸å¿ƒæœç´¢è¯è¯é¢‘ (Treemap)"""
    st.subheader("å›¾ 4: æ ¸å¿ƒæœç´¢è¯è¯é¢‘ (Top 10)")
    
    ecom_df = keyword_strategy['ç”µå•†å…³é”®è¯ (Top 10)'].copy()
    ecom_df['type'] = 'ç”µå•†æœç´¢'
    
    social_df = keyword_strategy['ç¤¾äº¤å…³é”®è¯ (Top 10)'].copy()
    social_df['type'] = 'ç¤¾äº¤æœç´¢'
    
    df = pd.concat([ecom_df, social_df])
    
    fig = px.treemap(df, path=[px.Constant("å…¨å¹³å°"), 'type', 'keyword'], 
                     values='count', color='count',
                     color_continuous_scale='Blues')
    fig.update_traces(textinfo="label+value+percent root")
    fig.update_layout(template=PLOT_TEMPLATE, margin=dict(t=50, l=0, r=0, b=0))
    st.plotly_chart(fig, use_container_width=True)

# --- 1B. å¸‚åœºæ ¼å±€å›¾è¡¨ (æ— æ”¹åŠ¨) ---
def plot_price_sales_matrix(df):
    """å›¾ 5: å¸‚åœºä»·æ ¼åŒºé—´åˆ†å¸ƒ"""
    st.subheader("å›¾ 5: å¸‚åœºä»·æ ¼åŒºé—´åˆ†å¸ƒ (æ°”æ³¡å¤§å° = æ€»é”€é‡)")
    bins = [0, 50, 100, 150, 200, 300, 1000]
    labels = ["0-50å…ƒ", "50-100å…ƒ", "100-150å…ƒ", "150-200å…ƒ", "200-300å…ƒ", "300+å…ƒ"]
    df['price_bin'] = pd.cut(df['price'], bins=bins, labels=labels, right=False)
    
    plot_data = df.groupby('price_bin', observed=True).agg(
        total_sales=('sales', 'sum'),
        product_count=('title', 'count')
    ).reset_index()
    
    fig = px.scatter(
        plot_data, x='price_bin', y='product_count', size='total_sales', size_max=70,
        color='price_bin', color_discrete_sequence=PLOT_COLOR_SEQUENCE,
        labels={'price_bin': 'ä»·æ ¼åŒºé—´', 'product_count': 'å•†å“é“¾æ¥æ•° (SKUæ•°)', 'total_sales': 'ä¼°ç®—æ€»é”€é‡'}
    )
    fig.update_layout(template=PLOT_TEMPLATE, yaxis_title='å•†å“é“¾æ¥æ•° (SKUæ•°)', legend_title_text='ä»·æ ¼åŒºé—´')
    st.plotly_chart(fig, use_container_width=True)

def plot_brand_top10(df):
    """å›¾ 6: çƒ­é”€å“ç‰Œ Top 10 (æŸ±çŠ¶å›¾)"""
    st.subheader("å›¾ 6: ç”µå•†çƒ­é”€å“ç‰Œ TOP 10 (æŒ‰ä¼°ç®—é”€é‡)")
    brand_df = df.explode('tag_brand').dropna(subset=['tag_brand'])
    brand_df = brand_df[brand_df['tag_brand'] != 'Other'] 
    brand_data = brand_df.groupby('tag_brand')['sales'].sum().nlargest(10).sort_values(ascending=True)
    
    fig = px.bar(
        brand_data, x='sales', y=brand_data.index, orientation='h',
        text='sales', color_discrete_sequence=[PLOT_COLOR] * 10
    )
    fig.update_traces(texttemplate='%{text:.2s}')
    fig.update_layout(template=PLOT_TEMPLATE, xaxis_title='ä¼°ç®—æ€»é”€é‡', yaxis_title=None, 
                      yaxis_automargin=True)
    st.plotly_chart(fig, use_container_width=True)

def plot_brand_treemap(df):
    """å›¾ 7: çƒ­é”€å“ç‰ŒçŸ©é˜µ (Treemap)"""
    st.subheader("å›¾ 7: ç”µå•†çƒ­é”€å“ç‰ŒçŸ©é˜µ (æŒ‰ä¼°ç®—é”€é‡)")
    brand_df = df.explode('tag_brand').dropna(subset=['tag_brand'])
    brand_df = brand_df[brand_df['tag_brand'] != 'Other']
    brand_data = brand_df.groupby('tag_brand')['sales'].sum().nlargest(15).reset_index()
    
    fig = px.treemap(brand_data, path=[px.Constant("æ‰€æœ‰å“ç‰Œ"), 'tag_brand'], 
                     values='sales', color='sales',
                     color_continuous_scale='Blues')
    fig.update_traces(textinfo="label+value+percent root")
    fig.update_layout(template=PLOT_TEMPLATE, margin=dict(t=50, l=0, r=0, b=0))
    st.plotly_chart(fig, use_container_width=True)


def plot_regional_competition(df):
    """å›¾ 8: åŒºåŸŸç«äº‰æ ¼å±€"""
    st.subheader("å›¾ 8: åŒºåŸŸç«äº‰æ ¼å±€ (SKUæ•° vs æ€»é”€é‡)")
    location_df = df[(df['location'] != 'æœªçŸ¥') & (df['location'] != 'æµ·å¤–') & (df['location'] != 'nan')].copy()
    
    plot_data = location_df.groupby('location').agg(
        total_sales=('sales', 'sum'),
        product_count=('title', 'count')
    ).reset_index()
    
    plot_data = plot_data[(plot_data['total_sales'] > 100000) & (plot_data['product_count'] > 50)]
    
    fig = px.scatter(
        plot_data, x='product_count', y='total_sales', size='total_sales', size_max=50,
        color='location', text='location',
        color_discrete_sequence=px.colors.qualitative.Pastel,
        labels={'product_count': 'å•†å“é“¾æ¥æ•° (SKUæ•°)', 'total_sales': 'ä¼°ç®—æ€»é”€é‡'},
        log_x=True, log_y=True
    )
    fig.update_traces(textposition='top center', textfont_size=10) 
    fig.update_layout(template=PLOT_TEMPLATE, showlegend=False, xaxis_title="SKUæ•° (è´§æºåœ°)", yaxis_title="æ€»é”€é‡ (å¸‚åœº)")
    st.plotly_chart(fig, use_container_width=True)

def plot_color_price_heatmap(df):
    """å›¾ 9: è‰²ç³»-ä»·æ ¼äº¤å‰çƒ­åŠ›å›¾"""
    st.subheader("å›¾ 9: è‰²ç³»-ä»·æ ¼äº¤å‰çƒ­åŠ›å›¾ (é”€é‡)")
    if 'price_bin' not in df.columns:
        bins = [0, 50, 100, 150, 200, 300, 1000] 
        labels = ["0-50å…ƒ", "50-100å…ƒ", "100-150å…ƒ", "150-200å…ƒ", "200-300å…ƒ", "300+å…ƒ"]
        df['price_bin'] = pd.cut(df['price'], bins=bins, labels=labels, right=False)
    
    color_df = df.explode('tag_color').dropna(subset=['tag_color'])
    color_df = color_df[color_df['tag_color'] != 'æœªæ˜ç¡®è‰²ç³»']
    
    heatmap_data = color_df.groupby(['tag_color', 'price_bin'], observed=True)['sales'].sum().reset_index()
    heatmap_pivot = heatmap_data.pivot_table(index='tag_color', columns='price_bin', values='sales', fill_value=0)
    
    fig = px.imshow(
        heatmap_pivot, text_auto='.2s', aspect="auto",
        color_continuous_scale='Blues',
        labels={'x': 'ä»·æ ¼åŒºé—´', 'y': 'è‰²ç³»', 'color': 'ä¼°ç®—æ€»é”€é‡'}
    )
    fig.update_layout(template=PLOT_TEMPLATE, xaxis_title="ä»·æ ¼åŒºé—´", yaxis_title="è‰²ç³»", 
                      yaxis_automargin=True)
    st.plotly_chart(fig, use_container_width=True)

# --- 1C. äº§å“æ·±åº¦æ‹†è§£ (æ— æ”¹åŠ¨) ---
def plot_color_share_donut(df):
    """å›¾ 10: ä¸»æµè‰²ç³»å¸‚åœºé”€é‡å æ¯”"""
    st.subheader("å›¾ 10: ä¸»æµè‰²ç³»å¸‚åœºé”€é‡å æ¯”")
    color_df = df.explode('tag_color').dropna(subset=['tag_color'])
    color_df = color_df[color_df['tag_color'] != 'æœªæ˜ç¡®è‰²ç³»'] 
    color_data = color_df.groupby('tag_color')['sales'].sum().reset_index()
    
    fig = px.pie(
        color_data, names='tag_color', values='sales',
        hole=0.4, color_discrete_sequence=PLOT_COLOR_SEQUENCE
    )
    fig.update_traces(textinfo='percent+label', pull=[0.05 if i == 0 else 0 for i in range(len(color_data))])
    fig.update_layout(template=PLOT_TEMPLATE, legend_title_text='è‰²ç³»')
    st.plotly_chart(fig, use_container_width=True)

def plot_product_archetype_matrix(df):
    """å›¾ 11: äº§å“ç±»å‹å®šä½çŸ©é˜µ (V2)"""
    st.subheader("å›¾ 11: äº§å“ç±»å‹å®šä½çŸ©é˜µ (æ°”æ³¡å¤§å° = SKUæ•°)")
    plot_data = df[df['archetype'] != 'å…¶ä»–'].groupby('archetype').agg(
        total_sales=('sales', 'sum'),
        avg_price=('price', 'mean'),
        product_count=('title', 'count')
    ).reset_index()

    fig = px.scatter(
        plot_data, x='total_sales', y='avg_price', size='product_count', size_max=60,
        color='archetype', text='archetype',
        color_discrete_sequence=PLOT_COLOR_SEQUENCE,
        labels={'total_sales': 'ä¼°ç®—æ€»é”€é‡', 'avg_price': 'å¹³å‡ä»·æ ¼ (å…ƒ)', 'archetype': 'äº§å“ç±»å‹'}
    )
    fig.update_traces(textposition='top center')
    fig.update_layout(template=PLOT_TEMPLATE, xaxis_title='å¸‚åœºè§„æ¨¡ (æ€»é”€é‡)', yaxis_title='ä»·æ ¼å®šä½ (å‡ä»·)', 
                      legend_title_text='äº§å“ç±»å‹')
    st.plotly_chart(fig, use_container_width=True)

def plot_efficacy_bubble(df):
    """å›¾ 12: æ ¸å¿ƒåŠŸæ•ˆè¯‰æ±‚å¸‚åœºè¡¨ç° (V1)"""
    st.subheader("å›¾ 12: æ ¸å¿ƒåŠŸæ•ˆè¯‰æ±‚å¸‚åœºè¡¨ç° (æ°”æ³¡å¤§å° = SKUæ•°)")
    tech_df = df.explode('tag_tech').dropna(subset=['tag_tech'])
    tech_df = tech_df[tech_df['tag_tech'] != 'åŸºç¡€æ¬¾']
    
    plot_data = tech_df.groupby('tag_tech').agg(
        total_sales=('sales', 'sum'),
        avg_price=('price', 'mean'),
        product_count=('title', 'count')
    ).reset_index()

    fig = px.scatter(
        plot_data, x='total_sales', y='avg_price', size='product_count', size_max=60,
        color='tag_tech', text='tag_tech',
        color_discrete_sequence=PLOT_COLOR_SEQUENCE,
        labels={'total_sales': 'ä¼°ç®—æ€»é”€é‡', 'avg_price': 'å¹³å‡ä»·æ ¼ (å…ƒ)', 'product_count': 'å•†å“é“¾æ¥æ•°'}
    )
    fig.update_traces(textposition='top center')
    fig.update_layout(template=PLOT_TEMPLATE, xaxis_title='ä¼°ç®—æ€»é”€é‡', yaxis_title='å¹³å‡ä»·æ ¼ (å…ƒ)', 
                      legend_title_text='åŠŸæ•ˆæ ‡ç­¾')
    st.plotly_chart(fig, use_container_width=True)

# --- 1D. ç¤¾åª’å£°é‡éªŒè¯ (æ— æ”¹åŠ¨) ---
def get_filtered_social_df(df, platform_choice):
    """è¾…åŠ©å‡½æ•°ï¼šè·å–è¿‡æ»¤åçš„ç¤¾äº¤DF"""
    if platform_choice == 'XHS':
        return df[df['platform'] == 'XHS'].copy()
    elif platform_choice == 'Weibo':
        return df[df['platform'] == 'Weibo'].copy()
    else:
        return df.copy()

def plot_social_hot_topics(df):
    """å›¾ 13: ç¤¾åª’çƒ­ç‚¹è¯é¢˜å£°é‡ (æ€»æåŠæ•°)"""
    st.subheader(f"å›¾ 13: ç¤¾åª’çƒ­ç‚¹è¯é¢˜å£°é‡ (æŒ‰æ€»æåŠæ¬¡æ•°)")
    
    tech_counts = df.explode('tag_tech')['tag_tech'].value_counts()
    tech_counts = tech_counts.drop('åŸºç¡€æ¬¾', errors='ignore')
    
    color_counts = df.explode('tag_color')['tag_color'].value_counts()
    color_counts = color_counts.drop('æœªæ˜ç¡®è‰²ç³»', errors='ignore')
    
    topic_df = pd.concat([
        tech_counts.nlargest(5).reset_index().rename(columns={'index': 'topic', 'tag_tech': 'topic', 'count': 'mentions'}),
        color_counts.nlargest(5).reset_index().rename(columns={'index': 'topic', 'tag_color': 'topic', 'count': 'mentions'})
    ])
    topic_df = topic_df.sort_values('mentions', ascending=False)
    
    fig = px.treemap(topic_df, path=[px.Constant("æ‰€æœ‰è¯é¢˜"), 'topic'], 
                     values='mentions', color='mentions',
                     color_continuous_scale='Blues')
    fig.update_traces(textinfo="label+value+percent root")
    fig.update_layout(template=PLOT_TEMPLATE, margin=dict(t=50, l=0, r=0, b=0))
    st.plotly_chart(fig, use_container_width=True)

def plot_social_brand_buzz_bar(df):
    """å›¾ 14: ç¤¾äº¤çƒ­é—¨å“ç‰Œ (æ¡å½¢å›¾)"""
    st.subheader(f"å›¾ 14: ç¤¾äº¤çƒ­é—¨å“ç‰Œ Top 10 (æŒ‰æ€»ç‚¹èµæ•°)")
    brand_df = df.explode('tag_brand').dropna(subset=['tag_brand'])
    brand_df = brand_df[brand_df['tag_brand'] != 'Other']
    brand_data = brand_df.groupby('tag_brand')['likes'].sum().nlargest(10).sort_values(ascending=True)
    
    fig = px.bar(
        brand_data, x='likes', y=brand_data.index, orientation='h',
        text='likes', color_discrete_sequence=[PLOT_COLOR] * 10
    )
    fig.update_traces(texttemplate='%{text:.2s}')
    fig.update_layout(template=PLOT_TEMPLATE, xaxis_title='æ€»ç‚¹èµæ•°', yaxis_title=None, 
                      yaxis_automargin=True)
    st.plotly_chart(fig, use_container_width=True)

def plot_social_topic_engagement(avg_likes_df):
    """å›¾ 15: ç¤¾åª’çƒ­ç‚¹è¯é¢˜å¹³å‡ç‚¹èµï¼ˆçƒ­åº¦ï¼‰"""
    st.subheader(f"å›¾ 15: ç¤¾åª’çƒ­ç‚¹è¯é¢˜å¹³å‡ç‚¹èµ (çƒ­åº¦)")
    
    # ç­›é€‰å‡ºæœ‰æ„ä¹‰çš„è¯é¢˜
    whitening_topic = avg_likes_df[avg_likes_df['topic'] == 'æ˜¾ç™½']
    
    all_tech_topics = list(data_processor.DEFINITIONS["TECH"].keys())
    top_tech = avg_likes_df[avg_likes_df['topic'].isin(all_tech_topics)].nlargest(5, 'avg_likes')
    
    all_color_topics = list(data_processor.DEFINITIONS["COLOR"].keys())
    top_color = avg_likes_df[avg_likes_df['topic'].isin(all_color_topics)].nlargest(5, 'avg_likes')
    
    plot_df = pd.concat([whitening_topic, top_tech, top_color]).drop_duplicates(subset=['topic'])
    plot_df = plot_df.sort_values('avg_likes', ascending=True)
    
    plot_df['color'] = plot_df['topic'].apply(lambda x: PLOT_COLOR if x == 'æ˜¾ç™½' else GRAY_COLOR)
    
    fig = px.bar(
        plot_df, x='avg_likes', y='topic', orientation='h',
        text='avg_likes', color='color',
        color_discrete_map={PLOT_COLOR: PLOT_COLOR, GRAY_COLOR: GRAY_COLOR},
        labels={'topic': 'è¯é¢˜', 'avg_likes': 'å¹³å‡ç‚¹èµæ•°'}
    )
    fig.update_traces(texttemplate='%{text:.0f}')
    fig.update_layout(template=PLOT_TEMPLATE, xaxis_title='å¹³å‡ç‚¹èµæ•°', yaxis_title=None, 
                      yaxis_automargin=True, showlegend=False)
    st.plotly_chart(fig, use_container_width=True)

# --- 1E. æ ¸å¿ƒæ´å¯Ÿ: "WHAT IS æ˜¾ç™½?" ---

@st.cache_data(show_spinner=False)
def get_network_graph_data(social_df, ecom_df, co_occurrence_data):
    """
    ã€ã€ã€ æ–°å¢ï¼šçŸ¥è¯†å›¾è°±æ•°æ®å¤„ç†å‡½æ•° ã€‘ã€‘ã€‘
    ä¸º "æ˜¾ç™½" è¯é¢˜æ„å»ºä¸€ä¸ªäºŒçº§ç½‘ç»œå›¾æ•°æ®
    """
    logging.info("å¼€å§‹æ„å»ºäºŒçº§çŸ¥è¯†å›¾è°±...")
    
    # 1. å®šä¹‰æ ¸å¿ƒèŠ‚ç‚¹ (Top 5 è‰²ç³», Top 5 å“ç‰Œ, Top 5 åŠŸæ•ˆ)
    top_colors = [tag for tag, count in co_occurrence_data['color'].most_common(5)]
    top_brands = [tag for tag, count in co_occurrence_data['brand'].most_common(5)]
    top_techs = [tag for tag, count in co_occurrence_data['tech'].most_common(5)]
    
    # é¢œè‰²æ˜ å°„
    color_map = {}
    for tag in top_colors: color_map[tag] = (data_processor.DEFINITIONS["COLOR"].get(tag, []), "è‰²ç³»", "#0068c9")
    for tag in top_brands: color_map[tag] = (data_processor.DEFINITIONS["BRAND"].get(tag, []), "å“ç‰Œ", "#42a5f5")
    for tag in top_techs: color_map[tag] = (data_processor.DEFINITIONS["TECH"].get(tag, []), "åŠŸæ•ˆ", "#90caf9")
    
    core_nodes = set(top_colors + top_brands + top_techs)
    
    # 2. ç­›é€‰å‡ºæ‰€æœ‰â€œæ˜¾ç™½â€çš„å¸–å­
    all_df = pd.concat([
        ecom_df[['tag_brand', 'tag_color', 'tag_tech', 'tag_whitening']],
        social_df[['tag_brand', 'tag_color', 'tag_tech', 'tag_whitening']]
    ])
    whitening_df = all_df[all_df['tag_whitening'] == True]

    # 3. è®¡ç®—èŠ‚ç‚¹å¤§å° (æ€»æåŠæ¬¡æ•°)
    node_sizes = Counter()
    
    # 4. è®¡ç®—è¾¹çš„æƒé‡ (äºŒçº§å…±ç°)
    edge_weights = Counter()
    
    for _, row in whitening_df.iterrows():
        tags_in_row = set()
        for tag in row['tag_color']:
            if tag in core_nodes: tags_in_row.add(tag)
        for tag in row['tag_brand']:
            if tag in core_nodes: tags_in_row.add(tag)
        for tag in row['tag_tech']:
            if tag in core_nodes: tags_in_row.add(tag)
        
        for tag in tags_in_row:
            node_sizes[tag] += 1
        
        # è®¡ç®—æ‰€æœ‰ç»„åˆçš„è¾¹
        for u, v in combinations(sorted(list(tags_in_row)), 2):
            edge_weights[(u, v)] += 1
            
    # 5. å‡†å¤‡ NetworkX æ•°æ®
    G = nx.Graph()
    
    # æ·»åŠ èŠ‚ç‚¹
    for tag, size in node_sizes.items():
        if tag in color_map:
            G.add_node(tag, size=size, type=color_map[tag][1], color=color_map[tag][2])
            
    # æ·»åŠ è¾¹
    for (u, v), weight in edge_weights.items():
        if u in G.nodes and v in G.nodes and weight > 1: # è¿‡æ»¤æ‰å¤ªå¼±çš„è¿æ¥
            G.add_edge(u, v, weight=weight)
            
    # 6. è®¡ç®—å¸ƒå±€
    # k æ˜¯èŠ‚ç‚¹é—´çš„ç†æƒ³è·ç¦»ï¼Œiterations æ˜¯è¿­ä»£æ¬¡æ•°
    # å¢åŠ  k å’Œ iterations å¯ä»¥è®©å›¾æ›´æ¾æ•£ï¼Œå‡å°‘é‡å 
    pos = nx.spring_layout(G, k=0.8, iterations=50, seed=42)
    
    return G, pos

def plot_whitening_network_graph(G, pos):
    """
    ã€ã€ã€ å…¨æ–°ï¼šåŠ›å¯¼å‘ç½‘ç»œå›¾ ã€‘ã€‘ã€‘
    å›¾ 16: "æ˜¾ç™½" æ ¸å¿ƒè¯é¢˜ç½‘ç»œå›¾ (NetworkX + Plotly)
    """
    st.subheader("å›¾ 16: â€œæ˜¾ç™½â€ æ ¸å¿ƒè¯é¢˜ç½‘ç»œå›¾ (äºŒçº§å…³è”)")
    
    # 1. å‡†å¤‡è¾¹çš„è½¨è¿¹
    edge_x, edge_y, edge_weights_norm = [], [], []
    max_weight = max((d['weight'] for u, v, d in G.edges(data=True)), default=1)
    
    for u, v, data in G.edges(data=True):
        edge_x.extend([pos[u][0], pos[v][0], None])
        edge_y.extend([pos[u][1], pos[v][1], None])
        # å½’ä¸€åŒ–çº¿å®½
        edge_weights_norm.append((data['weight'] / max_weight) * 10 + 0.5)

    # åˆ›å»ºå¤šä¸ª edge trace (Plotly Bug: æ— æ³•åœ¨ä¸€ä¸ªtraceä¸­æŒ‡å®šä¸åŒçº¿å®½)
    edge_traces = []
    i = 0
    for u, v, data in G.edges(data=True):
        edge_traces.append(go.Scatter(
            x=[pos[u][0], pos[v][0]],
            y=[pos[u][1], pos[v][1]],
            mode='lines',
            line=dict(width=edge_weights_norm[i], color=GRAY_COLOR),
            hoverinfo='text',
            text=f"å…±ç°: {data['weight']}"
        ))
        i += 1
        
    # 2. å‡†å¤‡èŠ‚ç‚¹è½¨è¿¹
    node_x, node_y, node_text, node_color, node_size = [], [], [], [], []
    max_size = max((d['size'] for n, d in G.nodes(data=True)), default=1)
    
    for node, data in G.nodes(data=True):
        node_x.append(pos[node][0])
        node_y.append(pos[node][1])
        node_color.append(data['color'])
        # å½’ä¸€åŒ–èŠ‚ç‚¹å¤§å°
        node_size.append((data['size'] / max_size) * 50 + 10)
        node_text.append(f"{node}<br>ç±»å‹: {data['type']}<br>æåŠ: {data['size']}")

    node_trace = go.Scatter(
        x=node_x, y=node_y,
        mode='markers+text',
        text=node_text,
        textposition="top center",
        marker=dict(
            color=node_color,
            size=node_size,
            line=dict(width=2, color='#333')
        ),
        hoverinfo='text'
    )
    
    # 3. ç»˜å›¾
    fig = go.Figure(data=edge_traces + [node_trace],
                 layout=go.Layout(
                    showlegend=False,
                    hovermode='closest',
                    margin=dict(b=20, l=20, r=20, t=40),
                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                    template=PLOT_TEMPLATE,
                    height=700 # ç»™äºˆæ›´å¤šç©ºé—´
                    ))
    st.plotly_chart(fig, use_container_width=True)


def plot_whitening_co_occurrence_bars(co_occurrence_data):
    """å›¾ 17: "æ˜¾ç™½" çš„å…·ä½“æ„æˆ (ä¸‰å°å›¾)"""
    st.subheader("å›¾ 17: â€œæ˜¾ç™½â€ çš„è¯­ä¹‰æ„æˆ (ä¸€çº§å…³è”, Top 5)")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        data = co_occurrence_data['color']
        if data:
            df = pd.DataFrame(data.most_common(5), columns=['tag', 'count'])
            fig = px.bar(df, x='count', y='tag', orientation='h', title="â€œæ˜¾ç™½â€è‰²ç³»",
                         color_discrete_sequence=[PLOT_COLOR])
            fig.update_layout(template=PLOT_TEMPLATE, yaxis_title=None, xaxis_title="å…±ç°æ¬¡æ•°", yaxis={'categoryorder':'total ascending'}, yaxis_automargin=True)
            st.plotly_chart(fig, use_container_width=True)
    with col2:
        data = co_occurrence_data['brand']
        if data:
            df = pd.DataFrame(data.most_common(5), columns=['tag', 'count'])
            fig = px.bar(df, x='count', y='tag', orientation='h', title="â€œæ˜¾ç™½â€å“ç‰Œ",
                         color_discrete_sequence=[PLOT_COLOR])
            fig.update_layout(template=PLOT_TEMPLATE, yaxis_title=None, xaxis_title="å…±ç°æ¬¡æ•°", yaxis={'categoryorder':'total ascending'}, yaxis_automargin=True)
            st.plotly_chart(fig, use_container_width=True)
    with col3:
        data = co_occurrence_data['tech']
        if data:
            df = pd.DataFrame(data.most_common(5), columns=['tag', 'count']) 
            fig = px.bar(df, x='count', y='tag', orientation='h', title="â€œæ˜¾ç™½â€åŠŸæ•ˆ",
                         color_discrete_sequence=[PLOT_COLOR])
            fig.update_layout(template=PLOT_TEMPLATE, yaxis_title=None, xaxis_title="å…±ç°æ¬¡æ•°", yaxis={'categoryorder':'total ascending'}, yaxis_automargin=True)
            st.plotly_chart(fig, use_container_width=True)

def plot_whitening_co_matrix(co_occurrence_data):
    """å›¾ 18: "æ˜¾ç™½" è‰²ç³»xåŠŸæ•ˆ å…±ç°çƒ­åŠ›å›¾"""
    st.subheader("å›¾ 18: â€œæ˜¾ç™½â€ è‰²ç³» x åŠŸæ•ˆ å…±ç°çƒ­åŠ›å›¾")
    matrix = co_occurrence_data.get('co_matrix')
    
    if matrix is None or matrix.empty:
        st.warning("å…±ç°çŸ©é˜µæ•°æ®ä¸è¶³ã€‚")
        return
        
    fig = px.imshow(
        matrix, text_auto=True, aspect="auto",
        color_continuous_scale='Blues',
        labels={'x': 'åŠŸæ•ˆæ ‡ç­¾', 'y': 'è‰²ç³»æ ‡ç­¾', 'color': 'å…±ç°æ¬¡æ•°'}
    )
    fig.update_layout(template=PLOT_TEMPLATE, xaxis_title="åŠŸæ•ˆæ ‡ç­¾", yaxis_title="è‰²ç³»æ ‡ç­¾", 
                      yaxis_automargin=True)
    st.plotly_chart(fig, use_container_width=True)

# --- 1F. å£ç¢‘éªŒè¯ (æ— æ”¹åŠ¨) ---
def plot_comment_sentiment(comments_insight):
    """å›¾ 19: çœŸå®è¯„è®ºæƒ…æ„Ÿå£°é‡"""
    st.subheader("å›¾ 19: çœŸå®è¯„è®ºæƒ…æ„Ÿå£°é‡ (935æ¡è¯„è®º)")
    
    col1, col2, col3 = st.columns(3)
    col1.metric("æ€»è¯„è®ºæ•°", f"{comments_insight['total_comments']} æ¡")
    col2.metric("æ­£é¢å£ç¢‘ (â€œæ˜¾ç™½â€)", f"{comments_insight['whitening_mentions']} æ¬¡", delta="æ­£é¢")
    col3.metric("è´Ÿé¢å£ç¢‘ (â€œæ˜¾é»‘â€)", f"{comments_insight['blackening_mentions']} æ¬¡", delta="è´Ÿé¢ (ç»å¯¹é›·åŒº)", delta_color="normal")
    
    ratio = comments_insight['whitening_mentions'] / max(1, comments_insight['blackening_mentions'])
    create_insight_box(
        f"<b>å£ç¢‘çº¢çº¿æ´å¯Ÿ:</b> åœ¨ç”¨æˆ·çš„çœŸå®åé¦ˆä¸­, â€œæ˜¾ç™½â€ (æ­£é¢) çš„æåŠæ¬¡æ•°æ˜¯ â€œæ˜¾é»‘â€ (è´Ÿé¢) çš„ **{ratio:.0f} å€**ã€‚è¿™è¯æ˜â€œæ˜¾é»‘â€æ˜¯ç”¨æˆ·ç»å¯¹çš„é›·åŒºå’Œæ ¸å¿ƒè´Ÿé¢å£ç¢‘æ¥æºã€‚"
    )

# --- 3. Streamlit ä»ªè¡¨ç›˜ä¸»åº”ç”¨ ---
def main():
    
    # --- 0. åŠ è½½æ•°æ®ä¸CSS ---
    load_css("style.css")
    try:
        data_pack = data_processor.load_and_process_data(Path('.'))
    except Exception as e:
        st.error(f"è‡´å‘½é”™è¯¯ï¼šæ•°æ®åŠ è½½æˆ–å¤„ç†å¤±è´¥ã€‚è¯·æ£€æŸ¥ JSON æ–‡ä»¶è·¯å¾„å’Œæ ¼å¼ï¼Œæˆ– data_processor_final.py è„šæœ¬ã€‚é”™è¯¯: {e}")
        st.exception(e)
        st.stop()
        
    ecom_df = data_pack['ecom']
    social_df_all = data_pack['social']
    social_avg_likes_all = data_pack['social_avg_likes']

    # --- 1. æ ‡é¢˜ä¸æ‰§è¡Œæ‘˜è¦ ---
    st.title("ğŸ¨ æŸ“å‘æ¶ˆè´¹å“å¸‚åœºæ·±åº¦æ´å¯ŸæŠ¥å‘Š (V-Final-4)")
    st.markdown("---")
    
    st.header("1. æ‰§è¡Œæ‘˜è¦ (Executive Summary)")
    create_insight_box(
        f"""
        æœ¬æŠ¥å‘ŠåŸºäºå¯¹ **{data_pack['raw_counts_kpi']['æ·˜å®å•†å“'] + data_pack['raw_counts_kpi']['äº¬ä¸œå•†å“']:,}** æ¡ç”µå•†å•†å“å’Œ **{data_pack['raw_counts_kpi']['å°çº¢ä¹¦ç¬”è®°'] + data_pack['raw_counts_kpi']['å¾®åšå¸–å­']:,}** æ¡ç¤¾åª’å¸–å­çš„æ·±åº¦åˆ†æï¼Œæ ¸å¿ƒç»“è®ºå¦‚ä¸‹ï¼š
        <br/><br/>
        1.  <b>å¸‚åœºåŸºæœ¬ç›˜:</b> `50-100å…ƒ` ä»·ä½æ®µçš„ `æ£•è‰²ç³»`ã€`ä¾¿æ·å‹(æ³¡æ²«)` äº§å“æ˜¯æ»¡è¶³å¤§ä¼—éœ€æ±‚çš„ç»å¯¹ä¸»åŠ›ã€‚
        2.  <b>ç«äº‰ä¸åŒºåŸŸ:</b> `æ¬§è±é›…` ä¸ `æ–½åè”»` åœ¨ç”µå•†é”€é‡ä¸Šé¥é¥é¢†å…ˆã€‚å¸‚åœºå‘ˆâ€œäº§é”€åˆ†ç¦»â€ï¼Œ`å¹¿ä¸œ` æ˜¯æœ€å¤§è´§æºåœ°ï¼Œè€Œ `æ±Ÿè‹`ã€`é‡åº†` å­˜åœ¨â€œè¶…çº§å–åœºâ€ã€‚
        3.  <b>äº§å“æœºä¼šç‚¹:</b> `å¥åº·å‹(æ¤ç‰©/æ— æ°¨)` æˆåŠŸå æ®äº†â€œé«˜å‡ä»·â€å¿ƒæ™ºï¼Œæ˜¯å“ç‰Œæº¢ä»·å‡çº§çš„æ–¹å‘ã€‚
        4.  <b>ç¤¾åª’å£°é‡ç‹:</b> `å°çº¢ä¹¦` æ˜¯æŸ“å‘è¯é¢˜çš„ç»å¯¹ä¸­å¿ƒã€‚`çˆ±èŒ‰è‰(ç¾å¦†ä»™)` æ˜¯ç¤¾åª’å£°é‡å† å†›ï¼Œè¿œè¶…å…¶ç”µå•†è¡¨ç°ï¼Œæ˜¯â€œç¤¾åª’ç§è‰â€çš„æ ‡æ†ã€‚
        5.  <b>æ ¸å¿ƒæ´å¯Ÿ (WHAT IS æ˜¾ç™½?):</b> â€œæ˜¾ç™½â€æ˜¯ç¬¬ä¸€åˆšéœ€ã€‚çŸ¥è¯†å›¾è°± (å›¾ 16) å’Œçƒ­åŠ›å›¾ (å›¾ 18) å…±åŒæ­ç¤ºäº†â€œæ˜¾ç™½â€çš„**æ ¸å¿ƒäºŒçº§å…³è”**ï¼š`æ³¡æ²«`ã€`æ£•è‰²ç³»` å’Œ `çˆ±èŒ‰è‰` æ˜¯â€œæ˜¾ç™½â€è¯é¢˜ç½‘ç»œä¸­æœ€ç´§å¯†çš„ä¸‰ä¸ªèŠ‚ç‚¹ã€‚
        6.  <b>å£ç¢‘çº¢çº¿:</b> â€œæ˜¾é»‘â€æ˜¯ç»å¯¹é›·åŒºã€‚åœ¨935æ¡è¯„è®ºä¸­ï¼Œâ€œæ˜¾ç™½â€è¢«æåŠ {data_pack['comments_insight']['whitening_mentions']} æ¬¡ï¼Œâ€œæ˜¾é»‘â€ä»… {data_pack['comments_insight']['blackening_mentions']} æ¬¡ã€‚
        """
    )
    
    st.markdown("---")

    # --- 2. åˆ†ææ–¹æ³•è®º ---
    st.header("2. åˆ†ææ–¹æ³•è®ºä¸æ•°æ®ç­–ç•¥")
    st.markdown("æˆ‘ä»¬çš„æ´å¯ŸåŸºäºä¸€å¥—ä¸¥è°¨çš„â€œå…³é”®è¯-çˆ¬å–-æ ‡ç­¾åŒ–-åˆ†æâ€æµç¨‹ï¼Œå°†æµ·é‡éç»“æ„åŒ–æ•°æ®è½¬åŒ–ä¸ºå•†ä¸šæ´å¯Ÿã€‚")
    
    col1, col2 = st.columns([1, 1.3])
    with col1:
        st.subheader("å›¾ 1: æ´å¯Ÿåˆ†ææµç¨‹")
        plot_methodology_flow() # å›¾ 1
    with col2:
        plot_meta_data_funnel(data_pack['raw_counts_kpi']) # å›¾ 2 (KPIå¡)
        plot_meta_source_volume(data_pack['raw_counts']) # å›¾ 3 (V2æŸ±çŠ¶å›¾)
        
    plot_keyword_analysis_treemap(data_pack['keyword_strategy']) # å›¾ 4 (Treemap)
    
    st.markdown("---")

    # --- 3. å¸‚åœºå®è§‚æ ¼å±€ï¼šé’±åœ¨å“ªé‡Œï¼Ÿ ---
    st.header("3. å¸‚åœºå®è§‚æ ¼å±€ï¼šé’±åœ¨å“ªé‡Œï¼Ÿ")
    st.markdown("æˆ‘ä»¬é¦–å…ˆåˆ†æç”µå•†å¤§ç›˜ï¼Œå›ç­”ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šä»€ä¹ˆä»·ä½å–å¾—å¥½ï¼Ÿ è°åœ¨å–ï¼Ÿ è´§ä»å“ªé‡Œæ¥ï¼Ÿ")
    
    plot_price_sales_matrix(ecom_df) # å›¾ 5
    
    col3, col4 = st.columns(2)
    with col3:
        plot_brand_top10(ecom_df) # å›¾ 6 (æŸ±çŠ¶å›¾)
    with col4:
        plot_brand_treemap(ecom_df) # å›¾ 7 (Treemap)
    
    plot_regional_competition(ecom_df) # å›¾ 8
    plot_color_price_heatmap(ecom_df) # å›¾ 9
    
    create_insight_box(
        """
        <b>æ ¼å±€æ´å¯Ÿ:</b>
        1.  <b>ä»·æ ¼å¸¦ (å›¾ 5):</b> `50-100å…ƒ` æ˜¯ç«äº‰æœ€æ¿€çƒˆçš„çº¢æµ·ï¼ŒSKUæ•°å’Œæ€»é”€é‡å‡æ˜¯ç¬¬ä¸€ã€‚`150-200å…ƒ` ä»·ä½æ®µæ˜¯æº¢ä»·æœºä¼šç‚¹ã€‚
        2.  <b>å“ç‰Œ (å›¾ 6 & 7):</b> ä¸¤ç§å›¾è¡¨å‡éªŒè¯ `æ¬§è±é›…` ä¸ `æ–½åè”»` æ„æˆç¬¬ä¸€æ¢¯é˜Ÿï¼Œé”€é‡æ–­å±‚é¢†å…ˆã€‚
        3.  <b>åŒºåŸŸ (å›¾ 8):</b> å¸‚åœºå‘ˆâ€œäº§é”€åˆ†ç¦»â€ã€‚`å¹¿ä¸œ` æ˜¯æœ€å¤§çš„â€œè´§æºé›†æ•£åœ°â€ï¼ˆSKUæœ€å¤šï¼‰ï¼Œè€Œ `æ±Ÿè‹`ã€`é‡åº†` åˆ™æ˜¯â€œè¶…çº§å–åœºâ€ï¼ˆSKUä¸å¤šï¼Œä½†æ€»é”€é‡æé«˜ï¼‰ã€‚
        4.  <b>è‰²ç³»-ä»·æ ¼ (å›¾ 9):</b> `æ£•è‰²ç³»` åœ¨ `50-100å…ƒ` ä»·ä½æ®µé”€é‡æœ€é«˜ã€‚è€Œ `äºšéº»/é’è‰²ç³»` å’Œ `ç°è‰²/è“è‰²ç³»` ç­‰â€œæ½®è‰²â€ï¼Œå…¶é”€å”®é«˜å³°å‡ºç°åœ¨ `100-150å…ƒ` ä»¥ä¸Šçš„ä»·ä½ã€‚
        """
    )
    
    st.markdown("---")
    
    # --- 4. äº§å“æ·±åº¦æ‹†è§£ï¼šä»€ä¹ˆåœ¨çƒ­å–ï¼Ÿ ---
    st.header("4. äº§å“æ·±åº¦æ‹†è§£ï¼šä»€ä¹ˆåœ¨çƒ­å–ï¼Ÿ")
    st.markdown("åœ¨ä¸»æµä»·ä½ä¸‹ï¼Œå…·ä½“æ˜¯å“ªäº›äº§å“å½¢æ€åœ¨é©±åŠ¨å¸‚åœºï¼Ÿ æˆ‘ä»¬å°†äº§å“å½’çº³ä¸ºäº”å¤§ç±»å‹è¿›è¡ŒçŸ©é˜µåˆ†æã€‚")

    col5, col6 = st.columns([1.2, 1])
    with col5:
        plot_product_archetype_matrix(ecom_df) # å›¾ 11
    with col6:
        plot_color_share_donut(ecom_df) # å›¾ 10
    
    plot_efficacy_bubble(ecom_df) # å›¾ 12
        
    create_insight_box(
        """
        <b>äº§å“æ´å¯Ÿ:</b>
        1.  <b>è‰²ç³» (å›¾ 10):</b> `æ£•è‰²ç³»` æ˜¯å¸‚åœºçš„ç»å¯¹åŸºæœ¬ç›˜ï¼Œå æ®è¿‘åŠé”€é‡ï¼Œæ˜¯å¤§ä¼—æ¶ˆè´¹è€…çš„â€œå®‰å…¨ç‰Œâ€ã€‚
        2.  <b>äº§å“ç±»å‹ (å›¾ 11):</b>
            * <b>è·‘é‡å† å†› (å³ä¸‹):</b> `ä¾¿æ·å‹(æ³¡æ²«)` æ‹¥æœ‰æœ€é«˜çš„å¸‚åœºè§„æ¨¡ï¼ˆæ€»é”€é‡ï¼‰ï¼Œä½†ä»·æ ¼åä½ã€‚
            * <b>æº¢ä»·è“æµ· (å·¦ä¸Š):</b> `å¥åº·å‹(æ¤ç‰©/æ— æ°¨)` é”€é‡ä¸é«˜ï¼Œä½†æˆåŠŸå æ®äº†â€œé«˜å‡ä»·â€å¿ƒæ™ºï¼Œæ˜¯å“ç‰Œå‡çº§æ–¹å‘ã€‚
            * <b>æ—¶å°šå…ˆé”‹ (ä¸­é—´):</b> `æ—¶å°šå‹(æ½®è‰²)` å¤„åœ¨ä¸­é—´åœ°å¸¦ï¼Œæ˜¯è¿æ¥å¤§ä¼—ä¸æº¢ä»·çš„å…³é”®ã€‚
        3.  <b>åŠŸæ•ˆ (å›¾ 12):</b> â€œæ³¡æ²«â€å‹äº§å“é”€é‡æœ€é«˜ã€‚â€œæ¤ç‰©â€å’Œâ€œæ— æ°¨â€ç­‰å¥åº·æ¦‚å¿µï¼Œåˆ™æˆåŠŸå®ç°äº†æ›´é«˜çš„â€œå¹³å‡æº¢ä»·â€ã€‚
        """
    )

    st.markdown("---")

    # --- 5. ç¤¾åª’å£°é‡éªŒè¯ï¼šäººä»¬åœ¨è°ˆè®ºä»€ä¹ˆï¼Ÿ ---
    st.header("5. ç¤¾åª’å£°é‡éªŒè¯ï¼šäººä»¬åœ¨è°ˆè®ºä»€ä¹ˆï¼Ÿ")
    
    platform_choice = st.radio(
        "é€‰æ‹©åˆ†æå¹³å°ï¼š",
        ('å…¨éƒ¨', 'XHS', 'Weibo'),
        horizontal=True,
        label_visibility="collapsed"
    )
    
    # æ ¹æ®é€‰æ‹©è¿‡æ»¤DF
    social_df = get_filtered_social_df(social_df_all, platform_choice)
    
    # åŠ¨æ€è¿‡æ»¤ avg_likes_df (å¦‚æœå¹³å°ä¸æ˜¯"å…¨éƒ¨"ï¼Œåˆ™é‡ç®—)
    if platform_choice == 'å…¨éƒ¨':
        social_avg_likes = social_avg_likes_all
        st.markdown(f"**å½“å‰å¹³å°: {platform_choice}** (å…± {len(social_df):,} æ¡å¸–å­)")
    else:
        # ã€ã€ã€ ä¿®å¤ï¼šé‡ç®—å¹³å‡ç‚¹èµ ã€‘ã€‘ã€‘
        # (è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„é‡ç®—ï¼Œä»¥ä¿è¯è¿‡æ»¤æœ‰æ•ˆ)
        avg_likes_data_filtered = data_processor.get_avg_likes_by_topic(social_df) # å‡è®¾ data_processor æœ‰è¿™ä¸ªå‡½æ•°
        social_avg_likes = pd.DataFrame(avg_likes_data_filtered).sort_values('avg_likes', ascending=False)
        st.markdown(f"**å½“å‰å¹³å°: {platform_choice}** (å…± {len(social_df):,} æ¡å¸–å­)")

    
    col7, col8 = st.columns(2)
    with col7:
        plot_social_hot_topics(social_df) # å›¾ 13
    with col8:
        plot_social_brand_buzz_bar(social_df) # å›¾ 14
        
    plot_social_topic_engagement(social_avg_likes) # å›¾ 15
    
    create_insight_box(
        """
        <b>ç¤¾åª’æ´å¯Ÿ:</b>
        1.  <b>çƒ­ç‚¹è¯é¢˜ (å›¾ 13):</b> åœ¨ç¤¾åª’ç«¯ï¼Œ`æ³¡æ²«`ã€`å…æ¼‚` ç­‰ä¾¿æ·æ€§åŠŸæ•ˆï¼Œä»¥åŠ `æ£•è‰²ç³»`ã€`äºšéº»/é’è‰²ç³»` ç­‰çƒ­é—¨è‰²ç³»æ˜¯è®¨è®ºçš„ç»å¯¹ä¸»æµã€‚
        2.  <b>å“ç‰Œ (å›¾ 14):</b> ç¤¾åª’å£°é‡ä¸ç”µå•†é”€é‡ **ä¸å®Œå…¨åŒ¹é…**ã€‚`çˆ±èŒ‰è‰`ï¼ˆç¾å¦†ä»™ï¼‰åœ¨ç¤¾åª’çš„å£°é‡æé«˜ï¼Œæ˜¯â€œç¤¾åª’çˆ†æ¬¾â€å“ç‰Œã€‚
        3.  <b>çƒ­åº¦ (å›¾ 15):</b> â€œæ˜¾ç™½â€æ˜¯ç¤¾åª’æµé‡å¯†ç ã€‚å…¶å¹³å‡ç‚¹èµæ•°æ˜¾è‘—é«˜äºå…¶ä»–æ‰€æœ‰å…·ä½“åŠŸæ•ˆæˆ–è‰²ç³»è¯é¢˜ï¼Œæ˜¯é©±åŠ¨ç¤¾äº¤çˆ†æ¬¾çš„æ ¸å¿ƒå¼•æ“ã€‚
        """
    )
    
    st.markdown("---")

    # --- 6. æ ¸å¿ƒæ´å¯Ÿï¼ˆThe 'Why'ï¼‰ï¼šâ€œæ˜¾ç™½â€æ˜¯ç¬¬ä¸€åˆšéœ€ ---
    st.header("6. æ ¸å¿ƒæ·±æŒ–ï¼šåˆ°åº•ä»€ä¹ˆæ‰æ˜¯â€œæ˜¾ç™½â€ï¼Ÿ")
    st.markdown("æˆ‘ä»¬å¯¹æ‰€æœ‰æåŠâ€œæ˜¾ç™½â€çš„æ•°æ®è¿›è¡Œäº†è¯­ä¹‰å…±ç°åˆ†æï¼Œæ„å»ºäº†å¦‚ä¸‹çš„äºŒçº§å…³è”çŸ¥è¯†å›¾è°±ã€‚")

    # ã€ã€ã€ æ ¸å¿ƒä¿®æ”¹ï¼šåœ¨è¿™é‡Œè®¡ç®—å¹¶ä¼ å…¥å›¾è°±æ•°æ® ã€‘ã€‘ã€‘
    G, pos = get_network_graph_data(social_df_all, ecom_df, data_pack['co_occurrence'])
    plot_whitening_network_graph(G, pos) # å›¾ 16 (å…¨æ–°åŠ›å¯¼å‘å›¾)
    
    col9, col10 = st.columns(2)
    with col9:
        plot_whitening_co_occurrence_bars(data_pack['co_occurrence']) # å›¾ 17 (ä¸‰å°å›¾)
    with col10:
        plot_whitening_co_matrix(data_pack['co_occurrence']) # å›¾ 18 (çƒ­åŠ›å›¾)
    
    create_insight_box(
        """
        <b>â€œæ˜¾ç™½â€ æ„æˆæ´å¯Ÿ (å›¾ 16, 17, 18):</b>
        * <b>å›¾ 17 (ä¸€çº§å…³è”):</b> â€œæ˜¾ç™½â€ä¸ `æ£•è‰²ç³»`ã€`çˆ±èŒ‰è‰`ã€`æ³¡æ²«` å…³è”æœ€å¼ºã€‚
        * <b>å›¾ 16 (äºŒçº§å…³è” - çŸ¥è¯†å›¾è°±):</b> **è¿™æ‰æ˜¯æ ¸å¿ƒï¼** èŠ‚ç‚¹å›¾å±•ç¤ºäº†è¿™äº›çƒ­é—¨æ ‡ç­¾**å½¼æ­¤ä¹‹é—´**çš„è”ç³»ã€‚æˆ‘ä»¬èƒ½æ¸…æ™°çœ‹åˆ°ä¸€ä¸ªç”± `æ³¡æ²«`ã€`æ£•è‰²ç³»`ã€`çˆ±èŒ‰è‰` æ„æˆçš„**å¼ºå…³è”â€œé“ä¸‰è§’â€**ã€‚
        * <b>å›¾ 18 (äºŒçº§å…³è” - çƒ­åŠ›å›¾):</b> çƒ­åŠ›å›¾é‡åŒ–äº†å›¾16çš„å‘ç°ï¼Œ`æ³¡æ²«` + `æ£•è‰²ç³»` çš„å…±ç°æ¬¡æ•°é¥é¥é¢†å…ˆã€‚**ç»“è®ºï¼š** æ¶ˆè´¹è€…è¦çš„â€œæ˜¾ç™½â€æ˜¯ä¸€ä¸ªâ€œè§£å†³æ–¹æ¡ˆâ€ï¼Œå³â€œ**çˆ±èŒ‰è‰çš„æ£•è‰²ç³»æ³¡æ²«æŸ“å‘å‰‚**â€ã€‚
        """
    )
    
    st.markdown("---")

    # --- 7. æœ€ç»ˆéªŒè¯ä¸ç»“è®º ---
    st.header("7. æœ€ç»ˆéªŒè¯ï¼šç”¨æˆ·å£ç¢‘ä¸ç»“è®º")
    
    plot_comment_sentiment(data_pack['comments_insight']) # å›¾ 19
    
    st.subheader("B. å½“å‰å±€é™ä¸æœªæ¥æ–¹å‘")
    create_insight_box(
        """
        æœ¬æ¬¡â€œé—ªç”µæŠ¥å‘Šâ€æ•°æ®é‡å……è¶³ï¼Œä½†ä»æœ‰å±€é™æ€§ï¼Œæœªæ¥å¯ä»ä»¥ä¸‹æ–¹å‘å®Œå–„ï¼š
        1.  <b>è¯„è®ºæ•°æ®é‡ä¸è¶³:</b> 935 æ¡è¯„è®ºåªèƒ½åšå®šæ€§æ´å¯Ÿã€‚æœªæ¥éœ€æ‰©å¤§è¯„è®ºçˆ¬å–é‡è‡³ 10ä¸‡+ çº§åˆ«ï¼Œä»¥æ„å»ºæ›´ç²¾å‡†çš„â€œè‚¤è‰²-å‘è‰²â€æ¨èæ¨¡å‹ã€‚
        2.  <b>å¾®åšæ•°æ®ä»·å€¼ä½:</b> (å¯åˆ‡æ¢å¹³å°æŸ¥çœ‹) å¾®åšæ•°æ®å¤šä¸ºè¥é”€å’Œæ–°é—»ï¼Œç”¨æˆ·UGCä»·å€¼è¿œä½äºå°çº¢ä¹¦ï¼Œæœªæ¥åº”å°†çˆ¬å–é‡å¿ƒ<b>å½»åº•è½¬å‘å°çº¢ä¹¦</b>ã€‚
        3.  <b>ç¼ºå¤±äº¬ä¸œè¯„è®º:</b> æœ¬æ¬¡åªåˆ†æäº†æ·˜å®è¯„è®ºï¼Œæœªèƒ½è·å–äº¬ä¸œçš„ `è¯„ä»·äººæ•°` å¯¹åº”çš„çœŸå®è¯„è®ºï¼Œç¼ºå¤±äº†äº¬ä¸œä¾§çš„å£ç¢‘éªŒè¯ã€‚
        """
    )

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    # åœ¨ data_processor_final.py ä¸­æ·»åŠ ä¸€ä¸ªå‡½æ•°ç”¨äºé‡ç®— avg_likes
    # ä¸ºç®€åŒ–æ¼”ç¤ºï¼Œè¿™é‡Œå‡è®¾ main() å¯ä»¥è®¿é—® data_processor å†…éƒ¨
    
    def get_avg_likes_by_topic(social_df):
        topic_likes = defaultdict(lambda: {'total_likes': 0, 'count': 0})
        defs = data_processor.DEFINITIONS
        
        whitening_likes = social_df[social_df['tag_whitening'] == True]['likes']
        topic_likes['æ˜¾ç™½'] = {'total_likes': whitening_likes.sum(), 'count': len(whitening_likes)}
        
        tech_df = social_df.explode('tag_tech')
        for tag in defs["TECH"].keys():
            likes = tech_df[tech_df['tag_tech'] == tag]['likes']
            topic_likes[tag]['total_likes'] += likes.sum()
            topic_likes[tag]['count'] += len(likes)
            
        color_df = social_df.explode('tag_color')
        for tag in defs["COLOR"].keys():
            likes = color_df[color_df['tag_color'] == tag]['likes']
            topic_likes[tag]['total_likes'] += likes.sum()
            topic_likes[tag]['count'] += len(likes)

        avg_likes_data = []
        for topic, data in topic_likes.items():
            if data['count'] > 0:
                avg_likes = data['total_likes'] / data['count']
                avg_likes_data.append({'topic': topic, 'avg_likes': avg_likes, 'count': data['count']})
        return avg_likes_data

    # å°†å‡½æ•°æ³¨å…¥ data_processor æ¨¡å—ï¼Œä»¥ä¾¿ main() å¯ä»¥è°ƒç”¨
    data_processor.get_avg_likes_by_topic = get_avg_likes_by_topic
    
    main()